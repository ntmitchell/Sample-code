{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the coffee production schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'../datasets/capstone/coffee harvest schedule.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b69315889092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoffee_harvest_schedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../datasets/capstone/coffee harvest schedule.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcoffee_harvest_schedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'../datasets/capstone/coffee harvest schedule.csv' does not exist"
     ]
    }
   ],
   "source": [
    "coffee_harvest_schedule = pd.read_csv(\"../datasets/capstone/coffee harvest schedule.csv\", index_col = 0)\n",
    "coffee_harvest_schedule.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determining seasons by month\n",
    "def get_season (month, hemisphere = None):\n",
    "    northern_hemisphere_seasons = {1: 'Winter', 2: 'Winter', 3: 'Winter', 4: 'Spring', 5: 'Spring', 6: 'Spring', 7: 'Summer', 8: 'Summer', 9: 'Summer', 10: 'Fall', 11: 'Fall', 12: 'Fall'}\n",
    "    southern_hemisphere_seasons = {7: 'Winter', 8: 'Winter', 9: 'Winter', 10: 'Spring', 11: 'Spring', 12: 'Spring', 1: 'Summer', 2: 'Summer', 3: 'Summer', 4: 'Fall', 5: 'Fall', 6: 'Fall'}\n",
    "\n",
    "    if hemisphere.lower() == \"northern\":\n",
    "        season = northern_hemisphere_seasons[month]\n",
    "    elif hemisphere.lower() == \"southern\":\n",
    "        season = southern_hemisphere_seasons[month]\n",
    "    \n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting date fraction to datetime\n",
    "def convert_date_fraction_series_to_datetime(series = None):\n",
    "    \n",
    "    # Separate month decimal and year\n",
    "    month_decimal = np.mod(series, 1)\n",
    "    year = (series - month_decimal).astype(int)\n",
    "    \n",
    "    # Convert month decimal to month integer (1 = January, 2 = February, etc.)\n",
    "    month = np.round(12 * month_decimal + 0.5).astype(int)\n",
    "    \n",
    "    # Concatenate the values together into a string\n",
    "    date = year.astype(str) + \"-\" + month.astype(str) + \"-01\"\n",
    "    \n",
    "    # Convert the date strings into datetime values\n",
    "    series = pd.to_datetime(date, yearfirst = True)\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def observation_in_harvest_season(temperature_data_row):\n",
    "    country = temperature_data_row[\"Country\"]\n",
    "    crop = (\"Robusta\", \"Arabica\")[temperature_data_row[\"Arabica Production\"]]\n",
    "    month = temperature_data_row.name.month\n",
    "#     crop = (\"Robusta\", \"Arabica\")[arabica_crop]\n",
    "    harvest_schedule = coffee_harvest_schedule[(coffee_harvest_schedule[\"Producing Country\"] == country) \n",
    "                                  & (coffee_harvest_schedule[crop])][[\"Harvest Begins\", \"Harvest Ends\"]]\n",
    "    harvest_month_range = harvest_schedule.values.tolist()[0]\n",
    "    return(harvest_month_range[0] <= month <= harvest_month_range[1])\n",
    "\n",
    "# observation_in_harvest_season(temperature_data[(temperature_data[\"Country\"] == \"Angola\") & (temperature_data.index.month == 4)].iloc[0])\n",
    "# for row in temperature_data[(temperature_data[\"Country\"] == \"Angola\")].iterrows():\n",
    "#     print(observation_in_harvest_season(row[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting weather stations by growing conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_station_data = pd.read_csv(\"../datasets/capstone/downloaded data/berkeley_earth_stations--site_detail.txt\", \n",
    "                               delimiter = \"\\t\", \n",
    "                               skiprows =148, \n",
    "                               names = [\"Station ID\", \n",
    "                                        \"Station Name\", \n",
    "                                        \"Latitude\", \n",
    "                                        \"Longitude\", \n",
    "                                        \"Elevation (m)\", \n",
    "                                        \"Lat. Uncertainty\", \n",
    "                                        \"Long. Uncertainty\", \n",
    "                                        \"Elev. Uncertainty (m)\", \n",
    "                                        \"Country\", \n",
    "                                        \"State / Province Code\", \n",
    "                                        \"County\", \n",
    "                                        \"Time Zone\", \n",
    "                                        \"WMO ID\", \n",
    "                                        \"Coop ID\", \n",
    "                                        \"WBAN ID\", \n",
    "                                        \"ICAO ID\", \n",
    "                                        \"# of Relocations\", \n",
    "                                        \"# Suggested Relocations\", \n",
    "                                        \"# of Sources\", \n",
    "                                        \"Hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_station_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "station_data = raw_station_data.copy()\n",
    "\n",
    "# Select only relevant columns\n",
    "station_data = station_data[[\"Station ID\", \"Station Name\", \"Latitude\", \"Longitude\", \"Elevation (m)\", \"Lat. Uncertainty\", \"Long. Uncertainty\", \"Elev. Uncertainty (m)\", \"Country\"]]\n",
    "\n",
    "# Convert values in numerical columns\n",
    "numeric_columns_in_stations_data = [\"Latitude\", \"Longitude\", \"Elevation (m)\", \"Lat. Uncertainty\", \"Long. Uncertainty\", \"Elev. Uncertainty (m)\"]\n",
    "station_data.loc[:, numeric_columns_in_stations_data] = station_data[numeric_columns_in_stations_data].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "# Remove whitespace from non-numerical columns\n",
    "station_data.loc[:, \"Station Name\"] = station_data[\"Station Name\"].str.strip()\n",
    "station_data.loc[:, \"Country\"] = station_data[\"Country\"].str.strip()\n",
    "\n",
    "# Filter data to select stations in coffee growing regions\n",
    "stations_in_coffee_producing_countries = station_data[station_data[\"Country\"].isin(coffee_harvest_schedule[\"Producing Country\"])]\n",
    "\n",
    "hemisphere_dictionary = (station_data.groupby(by = \"Country\")[\"Latitude\"].mean() > 0).map({True: \"Northern\", False: \"Southern\"}).to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making filter for coffee growing regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Arabica grows best in elevations 548 m – 1100 m for latitudes between 16° and 24°, or 1097 m – 1920 m for latitudes less that ±10°\n",
    "arabica_growing_conditions_criteria = (stations_in_coffee_producing_countries[\"Elevation (m)\"] >= 548) & (stations_in_coffee_producing_countries[\"Elevation (m)\"] <= 1100) & (stations_in_coffee_producing_countries[\"Latitude\"].abs() > 16) & (stations_in_coffee_producing_countries[\"Latitude\"].abs() <= 24)\n",
    "arabica_growing_conditions_criteria = arabica_growing_conditions_criteria | ((stations_in_coffee_producing_countries[\"Elevation (m)\"] >= 1097) & (stations_in_coffee_producing_countries[\"Elevation (m)\"] <= 1920) & (stations_in_coffee_producing_countries[\"Latitude\"].abs() <= 10))\n",
    "\n",
    "# Robusta grows best in elevations 0 m – 914 m in latitudes between ±10°\n",
    "robusta_growing_conditions_criteria = (stations_in_coffee_producing_countries[\"Elevation (m)\"] <= 914) & (stations_in_coffee_producing_countries[\"Latitude\"].abs() <= 10)\n",
    "\n",
    "# Select the stations in the ideal coffee growing regions\n",
    "stations_in_arabica_conditions = stations_in_coffee_producing_countries[arabica_growing_conditions_criteria][\"Station ID\"]\n",
    "stations_in_robusta_conditions = stations_in_coffee_producing_countries[robusta_growing_conditions_criteria][\"Station ID\"]\n",
    "\n",
    "stations_in_arabica_conditions_dictionary = dict.fromkeys(stations_in_arabica_conditions.values, True)\n",
    "stations_in_robusta_conditions_dictionary = dict.fromkeys(stations_in_robusta_conditions.values, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import raw temperature data from Berkeley Earth\n",
    "raw_temperature_data = pd.read_csv(\"../datasets/capstone/downloaded data/berkeley_earth -- data.txt\", \n",
    "            delimiter = \"\\t\",  \n",
    "            skiprows = 111, \n",
    "            names = [\"Station ID\", \n",
    "                     \"Series Number\", \n",
    "                     \"Date\", \n",
    "                     \"Temperature (C)\", \n",
    "                     \"Uncertainty (C)\", \n",
    "                     \"Observations\", \n",
    "                     \"Time of Observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_temperature_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temperatures_for_all_stations = raw_temperature_data.copy()\n",
    "\n",
    "# Remove unnecessary labels\n",
    "temperatures_for_all_stations.drop(labels = [\"Series Number\", \"Uncertainty (C)\", \"Observations\", \"Time of Observation\"], axis = 1, inplace = True)\n",
    "\n",
    "# Select the temperature data for stations in coffee growing regions, and add country names\n",
    "temperatures_for_coffee_producing_countries = temperatures_for_all_stations[temperatures_for_all_stations[\"Station ID\"].isin(stations_in_coffee_producing_countries[\"Station ID\"])]\n",
    "temperatures_for_coffee_producing_countries = stations_in_coffee_producing_countries[[\"Station ID\", \"Country\"]].merge(temperatures_for_coffee_producing_countries, on = \"Station ID\")\n",
    "\n",
    "# Add columns indicating each station's hemisphere (for seasonality calculations later)\n",
    "temperatures_for_coffee_producing_countries[\"Hemisphere\"] = temperatures_for_coffee_producing_countries[\"Country\"].map(hemisphere_dictionary)\n",
    "\n",
    "# Designate stations in areas that grow arabica and robusta coffee\n",
    "temperatures_for_coffee_producing_countries[\"Arabica Production\"] = temperatures_for_coffee_producing_countries[\"Station ID\"].map(stations_in_arabica_conditions_dictionary)\n",
    "temperatures_for_coffee_producing_countries[\"Robusta Production\"] = temperatures_for_coffee_producing_countries[\"Station ID\"].map(stations_in_robusta_conditions_dictionary)\n",
    "temperatures_for_coffee_producing_countries = temperatures_for_coffee_producing_countries.fillna(False)\n",
    "\n",
    "# Keep the stations in areas that grow arabica or robusta coffee\n",
    "temperature_data = temperatures_for_coffee_producing_countries[\n",
    "    temperatures_for_coffee_producing_countries[\"Arabica Production\"]\n",
    "    | temperatures_for_coffee_producing_countries[\"Robusta Production\"]]\n",
    "\n",
    "# Drop the Station ID column since it's no longer needed\n",
    "temperature_data.drop(\"Station ID\", axis = 1, inplace = True)\n",
    "\n",
    "# Convert dates to datetime values\n",
    "temperature_data.loc[:, \"Date\"] = convert_date_fraction_series_to_datetime(temperature_data[\"Date\"])\n",
    "\n",
    "# Index by date\n",
    "temperature_data.index = temperature_data[\"Date\"].values\n",
    "temperature_data = temperature_data.sort_index()\n",
    "temperature_data = temperature_data.drop(\"Date\", axis = 1)\n",
    "\n",
    "# Add seasons columns\n",
    "temperature_data[\"Season\"] = temperature_data.index.month\n",
    "temperature_data.loc[temperature_data[\"Hemisphere\"] == \"Northern\", \"Season\"] = temperature_data[temperature_data[\"Hemisphere\"] == \"Northern\"][\"Season\"].apply(lambda x: get_season(x, hemisphere = \"Northern\"))\n",
    "temperature_data.loc[temperature_data[\"Hemisphere\"] == \"Southern\", \"Season\"] = temperature_data[temperature_data[\"Hemisphere\"] == \"Southern\"][\"Season\"].apply(lambda x: get_season(x, hemisphere = \"Southern\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add frost likelihood\n",
    "temperature_data[\"Frost likelihood\"] = temperature_data[\"Temperature (C)\"] ** -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing stations in growing regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "arabica_producing_locations = pd.DataFrame(stations_in_arabica_conditions).merge(stations_in_coffee_producing_countries[[\"Station ID\", \"Latitude\", \"Longitude\"]], on = \"Station ID\")\n",
    "robusta_producing_locations = pd.DataFrame(stations_in_robusta_conditions).merge(stations_in_coffee_producing_countries[[\"Station ID\", \"Latitude\", \"Longitude\"]], on = \"Station ID\")\n",
    "\n",
    "arabica_longitudes = arabica_producing_locations[\"Longitude\"].tolist()\n",
    "arabica_latitudes = arabica_producing_locations[\"Latitude\"].tolist()\n",
    "\n",
    "robusta_longitudes = robusta_producing_locations[\"Longitude\"].tolist()\n",
    "robusta_latitudes = robusta_producing_locations[\"Latitude\"].tolist()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (10,16))\n",
    "station_map = Basemap()\n",
    "\n",
    "arabica_x, arabica_y = station_map(arabica_longitudes, arabica_latitudes)\n",
    "station_map.scatter(arabica_x, arabica_y, color='b')\n",
    "\n",
    "robusta_x, robusta_y = station_map(robusta_longitudes, robusta_latitudes)\n",
    "station_map.scatter(robusta_x, robusta_y, color='r')\n",
    "\n",
    "\n",
    "station_map.drawcoastlines()\n",
    "station_map.drawcountries()\n",
    "\n",
    "plt.title(\"Coffee growing regions in Berkeley Earth data\")\n",
    "plt.legend([\"Arabica\", \"Robusta\"], loc = 'center left')\n",
    "plt.show()\n",
    "\n",
    "# Show top growing countries, for comparison\n",
    "from IPython.display import Image\n",
    "Image(\"https://www.climate.gov/sites/default/files/CoffeeGrowingCountries_large.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting final temperatures dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temperature_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temperature_data.to_csv(\"../datasets/capstone/temperature-in-coffee-growing-regions--from-berkeley-earth.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
